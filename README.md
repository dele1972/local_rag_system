# Lokales AG System mit Ollama

Lokales RAG-System mit Ollama und LangChain. Viel SpaÃŸ beim lokalen Fragenstellen! ðŸ¤“

### Typische Limits fÃ¼r RAG-Systeme

- **DateigrÃ¶ÃŸe**:
    - Einzeldateien bis 50-100MB sind machbar
- **Gesamtmenge**:
    - Mehrere GB an Dokumenten sind mÃ¶glich
- **Anzahl Dateien**:
    - Tausende von Dateien sind kein Problem

## ðŸ—ï¸ System-Architektur

[architecture](docs/architecture.md)

## ðŸ“¦ Komponenten-Ãœbersicht

| Komponente          | Datei                 | Zweck                        |
|---------------------|-----------------------|------------------------------|
| **UI**              | `ui.py`               | Gradio Web-Interface         |
| **RAG Engine**      | `rag.py`              | Frage-Antwort-System         |
| **Document Loader** | `loader.py`           | Multi-Format-Dokumentenlader |
| **Vector Store**    | `vectorstore.py`      | Embeddings & ChromaDB        |
| **Config**          | `config.py`           | Zentrale Konfiguration       |
| **Connection**      | `connection_utils.py` | Ollama-Verbindungsmanagement |

## ðŸ”„ Datenfluss

1. **Dokumenten-Upload** â†’ Format-Erkennung â†’ Text-Extraktion â†’ Chunking â†’ Embeddings
2. **Frage-Input** â†’ Vektor-Suche â†’ Kontext-Assembly â†’ LLM-Query â†’ Antwort + Quellen

## ðŸ“‹ UnterstÃ¼tzte Formate

|    | Format         | Zweck                                      |
|----|----------------|--------------------------------------------|
| ðŸ“„ | **Text**       | `.txt`, `.md`                              |
| ðŸ“• | **PDF**        | Mit OCR-Support fÃ¼r gescannte Dokumente    |
| ðŸ“ | **Word**       | `.docx`, `.doc` (LibreOffice erforderlich) |
| ðŸ“Š | **Excel**      | `.xlsx`, `.xls`                            |
| ðŸ“ˆ | **PowerPoint** | `.pptx`, `.ppt` (LibreOffice erforderlich) |

## ðŸš€ Quick Start

### Voraussetzungen

**Hinweis**: Es wird vorausgesetzt, dass Ollama korrekt lÃ¤uft und die Modelle geladen werden kÃ¶nnen. Die Modelle mÃ¼ssen vorher Ã¼ber `ollama pull` heruntergeladen werden.

- Python 3.11 (Docker Container)
- Ollama (lokal installiert)
    - mit Modellen wie
        - [phi4-mini:3.8b](https://ollama.com/library/phi4-mini:3.8b)
        - [llama3](https://ollama.com/library/llama3.2:3b),
        - [mistral](https://ollama.com/library/mistral),
        - [deepseek-r1](https://ollama.com/library/deepseek-r1)
        - siehe [Perplexity Empfehlung](https://www.perplexity.ai/search/welches-ollama-modell-mit-bis-IK_81RgRRlGGwBkk38vR7w)
    - mit `ollama list` die Liste der installierten Modelle anzeigen
    - in `self.available_models = ["llama3.2", "mistral", "deepseek-r1"]` die Liste entsprechend anpassen

### 1. Start Backend (Docker)

#### 0 - Erstelle den Docker Container (sofern noch nicht vorhanden)
```
docker build -t lokales-rag-claude_v2 .
```

#### 1A - Starte das Backend (Variante A - per Docker Compose)
```
docker-compose up
```

#### 1B - Starte das Backend (Variante B - manuell)
```
docker run --add-host=host.docker.internal:host-gateway -v "./documents:/app/documents" -p 7860:7860 lokales-rag-claude_v2
```

### 2. OberflÃ¤che aufrufen

Dann Ã¶ffne deinen Browser unter: http://localhost:7860

## Nutzung
1. WÃ¤hle ein Modell aus (z.â€¯B. llama3)
2. Gib den Pfad zu deinen Dokumenten an (z.â€¯B. `./documents`)
3. Klicke auf "Laden"
4. Stelle eine Frage zu deinen Dokumenten

## ðŸ” Neue Debugging-Features:

### 1. Interaktive Debugging-Session

```bash
python main.py --debug-interactive
```

- MenÃ¼-gesteuertes Debugging
- Schritt-fÃ¼r-Schritt-Analyse
- Benutzerfreundliche Ausgaben

### 2. VollstÃ¤ndige System-Analyse

```bash
python main.py --analyze-system --path ./docs --model llama3.2
```

- 7-Phasen-Analyse-Pipeline
- Dokument â†’ Chunks â†’ Retrieval â†’ Performance
- Automatische Problembewertung
- JSON-Report-Export

### 3. Spezifische Analyse-Modi

```bash
# Nur Dokumente analysieren
python main.py --analyze-docs --path ./docs

# Chain-Empfehlungen
python main.py --chain-recommendation --model phi4-mini-reasoning:3.8b
```

### RAG Test Suite
- Komponenten: test_rag.py + test_utils.py + run_rag_tests.py
- Zweck: VollstÃ¤ndiges Test-Framework fÃ¼r RAG-System-Performance-Evaluation
- Optimiert fÃ¼r: Deutsche Dokumente, groÃŸe Dateien (6.5MB+), Ollama-Integration

#### TestdurchfÃ¼hrung

Ã–ffne ein Shell-Terminal zum Container:

```powershell
docker exec -it local_rag_system-rag-app-1 bash
```

##### 1. Erst analysieren (6.5MB Datei) âœ…

```bash
python run_rag_tests.py --analyze documents/large_german_doc.pdf
```

```powershell
docker exec -it local_rag_system-rag-app-1 python3 ./app/run_rag_tests.py --analyze documents/large_german_doc.pdf
```

##### 2. Quick-Test fÃ¼r erste EinschÃ¤tzung âŒ

```bash
python run_rag_tests.py --quick-test documents/large_german_doc.pdf
```

```powershell
docker exec -it local_rag_system-rag-app-1 python3 ./app/run_rag_tests.py --quick-test documents/large_german_doc.pdf
```

# 3. VollstÃ¤ndiger Benchmark

```bash
python run_rag_tests.py --benchmark --documents documents/ --output benchmark_results.json
```

```powershell
docker exec -it local_rag_system-rag-app-1 python3 ./app/run_rag_tests.py --benchmark --documents documents/ --output benchmark_results.json
```

#### ðŸ—ï¸ Gesamt-Architektur

##### 3-Schichten-Design

1. `test_rag.py` - Core Test Engine & Framework
2. `test_utils.py` - Utilities, Monitoring & Visualisierung
3. `run_rag_tests.py` - CLI Interface & Orchestrierung

##### Datenfluss

```
run_rag_tests.py â†’ test_rag.py â†’ test_utils.py
      â†“              â†“              â†“
  CLI/Setup    Test-Execution   Analysis/Viz
```

#### ðŸ“‹ Detaillierte Komponenten-Analyse
##### 1. `test_rag.py` - Core Test Framework
- ðŸŽ¯ Hauptzweck:
    - Systematische RAG-Performance-Tests mit konfigurierbaren Parametern
- ðŸ—ï¸ Kern-Klassen:
    - `TestConfiguration` - Test-Parameter-Definition
    - `TestResult` - Strukturierte Ergebnis-Sammlung
    - `RAGTestFramework` - Haupt-Test-Engine
- âš™ï¸ SchlÃ¼ssel-Methoden:
    - `create_test_configurations()` - Test-Matrix-Generierung
    - `run_single_test()` - Einzeltest-DurchfÃ¼hrung
    - `run_test_suite()` - VollstÃ¤ndige Test-Suite
    - `run_quick_comparison()` - Schneller Modell-Vergleich

##### 2. `test_utils.py` - Utilities & Analysis
- ðŸŽ¯ Hauptzweck:
    - Erweiterte Analyse, Monitoring und Visualisierung der Test-Ergebnisse
- ðŸ—ï¸ Kern-Klassen:
    - `DocumentMetrics` - Dokument-Analyse-Daten
    - `DocumentAnalyzer` - Vor-Test-Dokument-Bewertung
    - `PerformanceMonitor` - System-Resource-Ãœberwachung
    - `TestResultVisualizer` - Chart/Dashboard-Erstellung
    - `BatchTestRunner` - Parallelisierte Test-AusfÃ¼hrung
    - `ReportGenerator` - HTML-Report-Generierung
- âš™ï¸ Utility-Funktionen:
    - `quick_document_analysis()` - Schnelle Dokument-Bewertung
    - `estimate_test_duration()` - Test-Dauer-SchÃ¤tzung

##### 3. `run_rag_tests.py` - CLI & Orchestrierung (repariert)
- ðŸŽ¯ Hauptzweck:
    - Benutzerfreundliche CLI-Schnittstelle und Test-Orchestrierung
- ðŸ”§ Test-Modi:
    - `--analyze` - Dokument-Vorab-Analyse
    - `--quick-test` - Einzeldokument-Schnelltest
    - `--benchmark` - VollstÃ¤ndiger Performance-Benchmark
- âš™ï¸ Haupt-Funktionen:
    - `setup_test_environment()` - Umgebungs-Vorbereitung
    - `run_document_analysis()` - Dokument-Analyse-Pipeline
    - `run_quick_test()` - Quick-Test-Workflow
    - `run_full_benchmark()` - VollstÃ¤ndiger Benchmark-Workflow

#### ðŸŽ¯ Feature-Matrix der Gesamt-Komponente
##### ðŸ“Š Test-Capabilities:

- Systematische Parameter-Variation: Modelle Ã— Chunk-GrÃ¶ÃŸen Ã— Dokumente
- Deutsche Text-Optimierung: Angepasste Chunk-GrÃ¶ÃŸen (500-2000), Overlaps (50-200)
- GroÃŸe Datei-Support: Memory-optimiert fÃ¼r 6.5MB+ Dokumente
- Multi-Model-Support: Alle 4 Hauptmodelle (llama3.2, phi4-mini, mistral, deepseek-r1)

##### ðŸ” Analyse-Features:

- Dokument-Metriken: GrÃ¶ÃŸe, Token-SchÃ¤tzung, Sprach-Erkennung
- Performance-Monitoring: CPU/RAM-Ãœberwachung wÃ¤hrend Tests
- QualitÃ¤ts-Assessment: Response-Zeit, Antwort-Relevanz
- Batch-Processing: Parallelisierte Test-AusfÃ¼hrung

##### ðŸ“ˆ Visualisierung & Reports:

- Interactive Dashboards: Performance-Ãœbersicht mit Charts
- Model-Comparison-Charts: Detaillierte Modell-Vergleiche
- HTML-Reports: VollstÃ¤ndige Test-Dokumentation
- JSON-Export: Strukturierte Daten fÃ¼r weitere Analyse

##### ðŸ› ï¸ CLI-Interface:

- 3 Test-Modi: Analyse, Quick-Test, VollstÃ¤ndiger Benchmark
- Flexible Parameter: Modell-/Chunk-Auswahl via CLI
- Progress-Tracking: Echtzeit-Status-Updates
- Robust Error-Handling: Graceful Degradation bei Fehlern


#### ðŸ“¦ Integration & Dependencies

RAG-System-Integration:
```python
# AbhÃ¤ngigkeiten innerhalb des RAG-Systems
from app.config import config                    # Modell-Konfiguration
from app.rag import build_qa_chain              # Core RAG-FunktionalitÃ¤t  
from app.vectorstore import build_vectorstore   # Dokument-Processing
from app.connection_utils import check_ollama_connection  # Ollama-Integration
```

External Dependencies:
```python
# Visualisierung & Analyse
import matplotlib.pyplot as plt, seaborn as sns
import pandas as pd, numpy as np

# Performance-Monitoring  
import psutil, time

# Parallelisierung
from concurrent.futures import ThreadPoolExecutor
```

## Sonstiges

### Test, ob Ollama im Host erreichbar ist

```
curl http://localhost:11434/api/tags
```

### Docker Compose nach Ã„nderungen

```
docker-compose down
```

```
docker-compose build --no-cache
```

```
docker-compose up
```

### Sonstige Docker AktivitÃ¤ten

#### Docker auf Urzustand setzen (Alle Container, Images, etc. lÃ¶schen - bis auf aktive)

```
docker system prune -a --volumes
```

#### Alle Docker Container lÃ¶schen

Wenn zu viele verschiedene Docker Container mit Docker run gebildet wurden, kÃ¶nnen alle Docker Container mit diesem Befehl gelÃ¶scht werden:
```
docker builder prune --all --force
```

#### Container neu bauen:

```
docker build -t lokales-rag .
```
-> Danach wieder mit run starten


#### Docker
```
docker ps
docker stop <container-id>
docker rm <container-id>
docker run -v ... lokales-rag
```

## ðŸš¨ LÃ¶sung fÃ¼r aktuelle Hauptprobleme

### Problem 1: Token-Limit-Fehler

```
Token indices sequence length is longer than the specified maximum sequence length for this model (2367 > 1024)
```

**LÃ¶sung**: Die neue Analyse erkennt automatisch:
- Zu groÃŸe Chunks fÃ¼r Modell-Limits
- Empfiehlt `map_reduce` Chain fÃ¼r groÃŸe Dateien
- Zeigt Token-Effizienz-Probleme auf

### Problem 2: Schlechte Antworten bei 6.5MB Dateien

Die Analyse zeigt dir:
- Wie viele Dokumente tatsÃ¤chlich verwendet werden
- Retrieval-QualitÃ¤t (Similarity-Scores)
- Ob deutsche Embeddings fehlen
- Optimale k-Werte fÃ¼r dein System

### Problem 3: Chain-Typ-Optimierung

Automatische Empfehlung basierend auf:
- DateigrÃ¶ÃŸe (6.5MB â†’ map_reduce)
- Modell-Token-Limits
- Chunk-Anzahl

#### ðŸ“Š Beispiel-Analyse-Output:

```
ðŸ”¬ STARTE UMFASSENDE SYSTEM-ANALYSE
========================================
ðŸ“„ PHASE 1: DOKUMENT-ANALYSE
ðŸ“„ GROSSE DATEI: dokument.pdf (6.5MB)
ðŸ“Š SAMMLUNG-STATISTIKEN:
   Dateien: 3
   GesamtgrÃ¶ÃŸe: 8.2MB
   GroÃŸe Dateien (>5MB): 1

ðŸ§© PHASE 4: CHUNK-ANALYSE
ðŸ“Š Chunk-Statistiken: 234 Chunks, âŒ€ 1847 Zeichen
ðŸ’¡ CHUNK-EMPFEHLUNG: Chunks sind sehr lang - erwÃ¤gen Sie kleinere Chunk-GrÃ¶ÃŸen

â›“ï¸ PHASE 5: CHAIN-TYP-ANALYSE
ðŸŽ¯ EMPFOHLENER CHAIN-TYP: map_reduce (Konfidenz: 90%)

ðŸŽ¯ FINALE SYSTEM-BEWERTUNG
========================================
ðŸš¨ KRITISCHE PROBLEME:
   ðŸš¨ 1 groÃŸe Dateien (>5MB) detected
   âš ï¸ Zu viele Chunks fÃ¼r Token-Limit (4,096)
ðŸ’¡ EMPFEHLUNGEN:
   ðŸ’¡ Zwingend map_reduce Chain verwenden
   ðŸ’¡ Chunk-GrÃ¶ÃŸe fÃ¼r deutsche Texte optimieren
```

### ðŸš€ Sofortiger Nutzen:

FÃ¼hre sofort eine Analyse durch:

```bash
python main.py --analyze-system --path "pfad/zu/deinen/6.5MB/dateien" --model llama3.2 --verbose
```

FÃ¼r interaktive ProblemlÃ¶sung:

```bash
python main.py --debug-interactive
```

Die erweiterte `main.py` nutzt alle bereits implementierten Debugging-Klassen aus der `rag.py` optimal aus und gibt die notwendigen Einblicke, um das Problem mit groÃŸen deutschen Dokumenten zu lÃ¶sen.

## Scripts

### Automatisierte Dokumentation der app Python Dateien Â´/scripts/docgen.py`

#### ðŸŽ¯ Was das Script extrahiert

##### Struktur der generierten Dokumentation

- ðŸ“‹ Ãœbersicht - Dateiname, Zeilenzahl, Analysezeitpunkt
- ðŸ“¦ Imports - Kategorisiert in Standard Library, Third Party, Local/App
- ðŸ”§ Konstanten & Variablen - Top-Level Definitionen
- âš™ï¸ Funktionen - Signatur, Parameter, RÃ¼ckgabewerte, Beschreibung
- ðŸ—ï¸ Klassen - Vererbung, Methoden, Properties

##### Intelligente Extraktion

- Funktionssignaturen mit Typ-Annotations und Defaults
- Kurze Beschreibungen aus Docstrings oder Code-Analyse
- Kategorisierung (Ã¶ffentlich/privat, Properties, Decorators)
- Automatische GrÃ¶ÃŸenreduktion (typisch 60-80% kleiner)

#### ðŸš€ Verwendung

```powershell
docker exec -it local_rag_system-rag-app-1 python3 ./scripts/docgen.py
```

```bash
# Standard: ./app -> ./descr
python doc_generator.py
```

```bash
# Andere Verzeichnisse
python doc_generator.py --source ./my_app --output ./docs
```

```bash
# Nur bestimmte Dateien
python doc_generator.py --pattern "*_main.py"

```

## Changelog

[changelog](docs/changelog.md)